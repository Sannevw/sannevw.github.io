<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Sanne van Waveren</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Sanne van Waveren</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/sannevw.png" alt="Profile Picture of Sanne van Waveren" /></span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#cv">CV</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#thesisproposals">Master Thesis Proposals</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research">Research</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">Contact</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                  <img class="img-fluid img-logo mx-auto d-block" src="assets/img/logo.png" alt="Profile Picture of Sanne van Waveren" />
                  <h1 class="text-center">Gathering Collective Intelligence For Robots</h1>
                  <p class="text-center">Human-Robot Interaction, Social Robotics, Computer Science, Crowdsourcing, AI </p>
                    <!-- <h2 class="mb-0">
                        Sanne van Waveren
                    </h2> -->
                    <div class="text-center subheading mb-5">
                        <a href="https://scholar.google.com/citations?user=B80fZLUAAAAJ&hl=en">Link to Google Scholar --</a>
                        <a href="mailto:sannevw@kth.se">sannevw@kth.se</a>
                    </div>
                    <p class="text-justify lead mb-5">I am a PhD student at <a href="https://kth.se/is/rpl"> Robotics, Perception, and Learning (RPL)</a> at the Royal Institute of Technology (KTH), under the supervision of <a href="https://iolandaleite.com">dr. Iolanda Leite.</a> Previously, I obtained a computer science Master degree from the University of Twente in the Netherlands. My interests lie in the use of technology to enhance people’s lives. By combining social sciences and computer science, the goal of my PhD research is to develop social robots that can interact with people in an appropriate, effective, and efficient way over longer periods of time. </p>

                    <div class="d-flex justify-content-around">
                  <p class="bg-light text-black-50 text-justify w-50 ">
                  Looking to do your master thesis on Human-Robot Interaction? See my <a href="#thesisproposals"> master thesis proposals</a>, or feel free to contact me and tell me about your own idea.
                  </p>
                </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Experience-->
            <section class="resume-section" id="cv">
                <div class="resume-section-content">
                    <h2 class="mb-5">CV / Academic Service </h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Reviewer for Conference Proceedings</h3>
                            <!-- <div class="subheading mb-3">2019 -- Current</div> -->

                           <ul>
                             <li> ACM/IEEE International Conference on Human-Robot Interaction (HRI), 2019, 2020, 2021 Special recognition for outstanding review </li>
                             <li> ACM CHI Conference on Human Factors in Computing Systems (CHI), 2020 Special recognition for outstanding review </li>
                             <li> CogSci 2020, The 42nd Annual Meeting of the Cognitive Science Society </li>
                             <li> Robotics: Science and Systems, 2020 </li>
                             <li> ACM International Conference on Multimodal Interaction (ICMI), 2019, 2020 </li>
                             <li> International Conference on Affective Computing & Intelligent Interaction (ACII), 2019 </li>
                             <li> International Conference on Human-Agent Interaction (HAI), 2019 </li>
                             <li> ACM Interaction Design and Children (IDC) conference, 2019, 2020 </li>
                          </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">2019 - Present</span></div>
                      </div>
                      <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Reviewer for Journals</h3>
                            <!-- <div class="subheading mb-3">2019 -- Current</div> -->

                           <ul>
                             <li> Springer International Journal of Social Robotics, Impact Factor: 2.296 (2018) </li>
                             <li> IEEE Transactions on Affective Computing, Impact Factor: 6.288 (2020) </li>
                             <li> Frontiers in Robotics and AI, Impact Factor: 3.310 (2018) </li>
                             <li> Frontiers in Psychology, Impact Factor: 2.067 (2020) </li>
                          </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">2019 - Present</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                      <div class="flex-grow-1">
                        <h3 class="mb-0">Student Volunteer </h3>
                        <ul>
                        <li>
                          International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2018
                        </li>
                      </ul>
                      </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                      <div class="flex-grow-1">
                          <h3 class="mb-0">Student Supervision</h3>
                          <h4> Master Theses</h4>
                         <ul>
                           <li> Fredrik Sebek, Title: TBD, Feb 2021 – current </li>
                           <li> Rui Li, <i>Human Robot Interaction in Virtual Reality: Comparing human-robot proxemic behavior in reality versus virtual reality</i>, 2018 </li>
                        </ul>
                        <h4> Course Projects</h4>
                       <ul>
                         <li> DT2140 Multimodal Interaction and Interfaces —  Irene Kaklopoulou, Thays Santos Duarte, Ziyi Zhu, Yuqi Liu, Nov 2020-Jan 2021 </li>
                         <li> DD2411 Research project in Robotics, Perception and Learning — Oscar Örnberg, Feb-Sept 2019 </li>
                      </ul>
                      </div>
                      <div class="flex-shrink-0"><span class="text-primary">2019 - Present</span></div>
                  </div>

                  <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                      <h3 class="mb-0">Awards and Scholarships </h3>
                      <ul>
                      <li>
                        SIGAI ACM travel grant, 2019
                      </li>
                    </ul>
                    </div>
                  </div>

                  <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                      <h3 class="mb-0">Media Outreach / Public Events </h3>
                      <ul>
                      <li>
                        KTH Giants, November 2019
                      </li>
                    </ul>
                    </div>
                  </div>

                  <div class="embed-responsive embed-responsive-16by9 w-50 mx-auto d-block">
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/Vqg08iNuXDo" alt="An introduction video to our work in the Robotics, Perception, and Learning Division." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>



                    <!-- <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Web Developer</h3>
                            <div class="subheading mb-3">Intelitec Solutions</div>
                            <p>Capitalize on low hanging fruit to identify a ballpark value added activity to beta test. Override the digital divide with additional clickthroughs from DevOps. Nanotechnology immersion along the information highway will close the loop on focusing solely on the bottom line.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">December 2011 - March 2013</span></div>
                    </div> -->
                    <!-- <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Junior Web Designer</h3>
                            <div class="subheading mb-3">Shout! Media Productions</div>
                            <p>Podcasting operational change management inside of workflows to establish a framework. Taking seamless key performance indicators offline to maximise the long tail. Keeping your eye on the ball while performing a deep dive on the start-up mentality to derive convergence on cross-platform integration.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">July 2010 - December 2011</span></div>
                    </div> -->
                    <!-- <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Web Design Intern</h3>
                            <div class="subheading mb-3">Shout! Media Productions</div>
                            <p>Collaboratively administrate empowered markets via plug-and-play networks. Dynamically procrastinate B2C users after installed base benefits. Dramatically visualize customer directed convergence without revolutionary ROI.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2008 - June 2010</span></div>
                    </div> -->
                </div>
            </section>
            <hr class="m-0" />
            <!-- Education-->
            <section class="resume-section" id="publications">
                <div class="resume-section-content">
                    <h2 class="mb-5">Publications</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Conference Papers</h3>
                            <div class="subheading mb-3">Full-Length, Peer-reviewed</div>

                            <div class="text-justify">
                            <ul>
                            <li class="mt-2"> <div class="award"> Taras Kucherenko, Patrik Jonell, <b>Sanne van Waveren</b>, Gustav Eje Henter, Simon Alexanderson, Iolanda Leite, and Hedvig Kjellström. Gesticulator: A framework for semantically-aware speech-driven gesture generation. International Conference on Multimodal Interaction (ICMI ‘20). 2020. <img class="img-fluid img-profile rounded-circle mx-auto w-3 h-3" src="assets/img/award.png" alt="Medal Icon" />  Best Paper Award. <a href="https://dl.acm.org/doi/10.1145/3382507.3418815"> Link to paper -- </a> <a href="https://github.com/svito-zar/Gesticulator"> Link to code --</a> <a href="https://svito-zar.github.io/gesticulator/"> Link to project page</a>. </div> </li>

                            <li class="mt-2">
                              Kontogiorgos, D., <b>van Waveren, S.</b>, Wallberg, O., Abelho Pereira, A. T., Leite, I., & Gustafson, J. (2020). Embodiment Effects in Interactions with Failing Robots. In <i>SIGCHI Conference on Human Factors in Computing Systems (CHI)</i>. <a href="https://dl.acm.org/doi/abs/10.1145/3313831.3376372?casa_token=iXfBHqarN9wAAAAA:HPLjOdXA_35vgvhd69amJCto7HGMTJ7ouN8hBTVGXvG3z3ZJ53o9dRhDB34ahWyqiFn0KcSHaV8" > Link to paper</a> <a href="https://www.youtube.com/watch?v=MxGerI0Bc-U&feature=youtu.be"> Link to video </a> [<i>Acceptance rate 24.3%</i>]
                            </li>

                            <li class="mt-2">
                              Kontogiorgos, D., Pereira, A., Sahindal, B., <b>van Waveren, S.</b>, & Gustafson, J. (2020, March). Behavioural Responses to Robot Conversational Failures. In <i>Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction</i> (pp. 53-62). <a href="https://dl.acm.org/doi/abs/10.1145/3319502.3374782" > Link to paper</a>
                            </li>
                            </ul>
                          </div>

                            <!-- <p>GPA: 3.23</p> -->
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">2020</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"></h3>
                            <div class="subheading mb-3"></div>

                            <div class="text-justify">
                            <ul>
                            <li class="mt-2">
                            Li, R., van Almkerk, M., <b>van Waveren, S.</b>, Carter, E., & Leite, I. (2019, March). Comparing Human-Robot Proxemics between Virtual Reality and the Real World. In <i>2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</i> (pp. 431-439). IEEE. <a href="https://ieeexplore.ieee.org/abstract/document/8673116"> Link to paper</a> [<i>Acceptance rate 24%</i>]
                            </li>

                            <li class="mt-2">
                              <b>van Waveren, S.</b>, Carter, E. J., & Leite, I. (2019, July). Take One For the Team: The Effects of Error Severity in Collaborative Tasks with Social Robots. In <i>Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents</i> (pp. 151-158). ACM. <a href="https://dl.acm.org/doi/10.1145/3308532.3329475" >Link to paper </a> [<i>Acceptance rate 24%</i>]
                            </li>

                            <li class="mt-2">
                              <b>van Waveren S.</b>, Björklund L., Carter E.J., Leite I. (2019). In: Salichs M. et al. (eds) Social Robotics. ICSR 2019. Lecture Notes in Computer Science, vol 11876. Springer, Cham Link to paper [<i>Acceptance rate 75% </i>]
                            </li>
                            </ul>
                          </div>

                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">2019</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Workshop Papers</h3>
                            <div class="subheading mb-3">Peer-reviewed</div>

                            <div class="text-justify">
                            <ul>
                            <li class="mt-2">
                            Joosse, M. P., <b>van Waveren, S.</b>, Zaga, C., & Evers, V. (2017) Groups in Conflict at the Airport: How Everyday People Think a Robot Should Act. Poster presented at the CSCW’17 Workshop on Robots in Groups and Teams. <a href="https://cpb-us-w2.wpmucdn.com/sites.coecis.cornell.edu/dist/c/16/files/2017/01/Joosse-van-Waveren-Zaga-and-Evers-29wd7w7.pdf" > Link to Paper </a>
                            </li>

                            </ul>
                          </div>

                </div>
            </section>
            <hr class="m-0" />
            <!-- Skills-->
            <section class="resume-section" id="thesisproposals">
                <div class="resume-section-content">
                    <h2 class="mb-5">Master Thesis Proposals</h2>
                    <p class="text-justify">
                    I am continuously looking for highly motivated, independent masters students who are interested in (i) developing new algorithms and crowdsourcing approaches and (ii) implementing this in simulation or on a real robot, with the aim of efficiently authoring and verifying new robot behaviors for human-robot interaction. If you are interested, feel free to contact me.
                    </p>
                    <p>
                      I will be your daily supervisor and Associate Professor Dr. <a href="https://iolandaleite.com/">Iolanda Leite</a> will be your examiner.
                    </p>
                    <h3 class="mb-5">Proposals </h3>
                    <h4 class="mb-5">PROP 1. Human-Centered Approach for Semi-situated Robot Learning through Crowdsourcing </h4>
                    <p> As robots move out of controlled industrial environments into the real world, a persistent challenge is the need to expand behavioral policies on a large scale without constant expert supervision. To this end, this thesis explores opportunities for crowdsourcing,  a method that has been key to some recent breakthroughs in computer vision, to gather new robot behavior. One challenge is how, with partial information about the robot environment, people can provide the robot with useful input when it gets stuck to speed up the learning process. Such semi-situated robot learning has shown promising for gathering verbal and non-verbal dialog behaviors for repeated interactions with humans [1]. In this thesis, the goal is to:
                    </p>
                    <ul>
                      <li>
                      Familiarize with the existing literature on non-expert robot programming and crowdsourcing HRI; starting literature will be provided, but it is expected that a full literature review is done as a basis for the thesis;
                      </li>
                      <li>
                        Identify an opportunity for robot teaching through crowdsourcing;
                      </li>
                      <li>
                        Implement a running example of the crowdsourcing pipeline.
                      </li>
                    </ul>

                    <p>Prerequisites:</p>
                    <ul><li>
                    Good programming knowledge (Javascript, Python)
                    </li> </ul>
                    <p>
                      [1] Leite, I., Pereira, A., Funkhouser, A., Li, B., & Lehman, J. F. (2016, October). Semi-situated learning of verbal and nonverbal content for repeated human-robot interaction. In <i>Proceedings of the 18th ACM International Conference on Multimodal Interaction </i> (pp. 13-20).
                    </p>

                    <h4 class="mb-5  mt-5">PROP 2. Perceived Safety in Human-Drone Interaction</h4>

                    <p>
                      Safety is crucial when it comes to the deployment of robots in the real world. A special case is when a robot operates in an environment that is shared with people, people who can be seen as agents with their own intentions, beliefs, and actions that the robot needs to anticipate. This raises new questions related to the verification of robot behaviors [1].</p>
                      <p>
                      Human-Drone Interaction is increasingly receiving attention as drones are entering spaces that they will share with people. Drones can be for example used for surveillance of a construction site, to make an inventory of materials and report progress. In such scenarios, it is crucial to fly around and interact with humans in a comfortable and socially acceptable way. The goal of this thesis is to:

                    </p>

                  <ul>
                    <li>
                      Familiarize with the existing literature on human-drone interaction in relation to perceived safety, starting literature will be provided, but it is expected that a full literature review is done as a basis for the thesis;
                    </li>
                      <li>
                    Identify an opportunity to enhance perceived safety in HDI;
                  </li>
                    <li>
                    Design and implement a user study to evaluate the proposed opportunity with real people.
                  </li>
                  </ul>
                    Prerequisites:
                    <ul><li>
                    Good programming knowledge (Python and/or C++)</li>
                    <li>
                      Interest in human-robot interaction studies
                    </li>
                  </ul>
                    <p>
                    [1]  Alami, R., Eder, K. I., Hoffman, G., & Kress-Gazit, H. (2019). Verification and Synthesis of Human-Robot Interaction (Dagstuhl Seminar 19081). In Dagstuhl Reports (Vol. 9, No. 2). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.
                  </p>

                  <h4 class="mb-5 mt-5">PROP 3. Synthesis-Aided Non-experts Robot Programming</h4>
                  <p> To date, robot programming has primarily been a task for engineers, requiring a high level of mathematical and programming knowledge. Recently, an increasing body of work has focused on approaches to quickly and intuitively allow non-experts to program robots [e.g., 1,2,3,4]. One challenge is what parts of the programming process can be automated; specifically, how we can capture human input and translate it into specifications used for synthesis [5]. The goal of this master thesis is to: </p>

                  <ul><li>
                    Familiarize with the existing literature on non-expert robot programming and program synthesis, starting literature will be provided, but it is expected that a full literature review is done as a basis for the thesis;</li>
                    <li>
                    Identify an opportunity for applying synthesis to improve the process of synthesis-aided robot programming;</li>
                    <li>
                    Implement a running example and ideally, evaluate its effectiveness. </li>
                  </li></ul>

                <p>  Prerequisites: </p>

                <ul><li>
                  Good programming knowledge;
                </li>
                  <li>Knowledge of formal methods: program synthesis and verification.</li>
              </ul>
              <p>
                [1] Orendt, E. M., Fichtner, M., & Henrich, D. (2016, August). Robot programming by non-experts: intuitiveness and robustness of one-shot robot programming. In <i>2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) </i> (pp. 192-199). IEEE.
              </p>
              <p>
                [2] Liang, Y. S., Pellier, D., Fiorino, H., & Pesty, S. (2017). Evaluation of a robot programming framework for non-experts using symbolic planning representations. In <i>2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) </i> (pp. 1121-1126). IEEE.
              </p>

              <p>
                3] Sefidgar, Y. S., & Cakmak, M. (2018, March). End-user programming of manipulator robots in situated tangible programming paradigm. In <i>Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction </i> (pp. 319-320).
              </p>

              <p>
                [4] Stenmark, M., Haage, M., & Topp, E. A. (2017, March). Simplified programming of re-usable skills on a safe industrial robot: Prototype and evaluation. In <i> Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction  </i> (pp. 463-472). </p>

              <p> [5]  Alami, R., Eder, K. I., Hoffman, G., & Kress-Gazit, H. (2019). Verification and Synthesis of Human-Robot Interaction (Dagstuhl Seminar 19081). In <i>Dagstuhl Reports</i> (Vol. 9, No. 2). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik. </p>

              <h4 class="mb-5  mt-5">PROP 4. Natural Person-Following Behavior for Robots</h4>
              <p>
                Mobile robots are increasingly deployed in spaces that they will share with humans and, in addition to purely technical safety guarantees, it is crucial to endow these robots with socially acceptable navigation skills. For example, the robot needs to behave such that it is perceived as socially normative and does not cause discomfort in the people it shares the space with. For example, the term proxemics (i.e., the social use of space) was coined by Hall [1] and defines four personal space zones ranging from intimate (0-0.45 meter) to public (> 3.6 meter), which can be critical for successful HRI [2].
              </p>

              <p>
                Prior work has explored different person-following behaviors and studied the effect of various aspects, such as different person-tracking algorithms, relative angle, velocity, acceleration. Gockley at al. [3] studied how human-likeness, personal space, reliability, and safety affected a robot’s person-following behaviors: one following the exact path of the person and the other following in the direction of the person. Results showed that direction-following behavior appeared more natural and human-like and more closely matched people’s expectations. In this thesis, the goal is to:
              </p>

              <ul>
                <li> Familiarize with the existing literature on proxemics in person-following HRI scenarios, starting literature will be provided, but it is expected that a full literature review is done as a basis for the thesis; </li>
                <li>Identify factors in the robot’s following behavior that may influence people’s perceived comfort, perceived safety, or other subjective measures; </li>
                <li> Design and implement a user study to evaluate how these factors influence how people perceive the robot in a person-following interaction. </li>
              </ul>

              <p>Prerequisites:</p>
              <ul>
                <li> Good programming knowledge (Python); </li>
                <li>Interest in human-robot interaction studies; </li>
                <li>Experience with robots is a plus. </li>
              </ul>

              <p>
                [1]  Hall, E. T. (1966). <i>The hidden dimension</i> (Vol. 609). Garden City, NY: Doubleday.
              </p>
              <p>
                [2] Mead, R., & Matarić, M. J. (2016). Perceptual models of human-robot proxemics. In <i>Experimental Robotics</i> (pp. 261-276). Springer, Cham.</p>
                <p>
                  [3] Gockley, R., Forlizzi, J., & Simmons, R. (2007, March). Natural person-following behavior for social robots. In <i>Proceedings of the ACM/IEEE international conference on Human-robot interaction </i> (pp. 17-24). </p>
                  <p>
                    [4] Scales, P., Aycard, O., & Auberge, V. (2020). Studying Navigation as a Form of Interaction: a Design Approach for Social Robot Navigation Methods. In <i>IEEE International Conference on Robotics and Automation (ICRA). </i> </p>
                    <!-- <div class="subheading mb-3">Programming Languages & Tools</div>
                    <ul class="list-inline dev-icons">
                        <li class="list-inline-item"><i class="fab fa-html5"></i></li>
                        <li class="list-inline-item"><i class="fab fa-css3-alt"></i></li>
                        <li class="list-inline-item"><i class="fab fa-js-square"></i></li>
                        <li class="list-inline-item"><i class="fab fa-angular"></i></li>
                        <li class="list-inline-item"><i class="fab fa-react"></i></li>
                        <li class="list-inline-item"><i class="fab fa-node-js"></i></li>
                        <li class="list-inline-item"><i class="fab fa-sass"></i></li>
                        <li class="list-inline-item"><i class="fab fa-less"></i></li>
                        <li class="list-inline-item"><i class="fab fa-wordpress"></i></li>
                        <li class="list-inline-item"><i class="fab fa-gulp"></i></li>
                        <li class="list-inline-item"><i class="fab fa-grunt"></i></li>
                        <li class="list-inline-item"><i class="fab fa-npm"></i></li>
                    </ul>
                    <div class="subheading mb-3">Workflow</div>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Mobile-First, Responsive Design
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Cross Browser Testing & Debugging
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Cross Functional Teams
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Agile Development & Scrum
                        </li>
                    </ul> -->
                </div>
            </section>
            <hr class="m-0" />
            <!-- Interests-->
            <section class="resume-section" id="research">
                <div class="resume-section-content">
                    <h2 class="mb-5">Research</h2>
                    <h3 class="mb-5"> Current -- Gather Collective Intelligence for Robots </h3>
                    <p class="text-justify"> My current work revolves around enabling robots to gather additional behaviors during deployment. It is impossible to anticipate all possible cases at which a robot/interaction may breakdown. Endowing robots with the ability to collect additional input on the fly is therefore crucial for them to succeed in the real world. I am interested in how we can exploit our ‘collective intelligence’ (common knowledge) to let non-experts (people without programming or robotics experience) provide input to the robot.
                    </p>
                    <p class="text-justify"> In the real world, robots will encounter many new situations to which they need to adapt and respond. We, humans, are rather successful at adapting in new situations, and have substantial knowledge on what is socially acceptable and what is not. Currently, we are exploring the use of collective intelligence – the intelligence that we, humans, collectively have – for social robots. If a robot fails, because it does not know what to do or how to act, can someone without (robotic) programming skills help the robot to resolve the failure? For example, by providing the robot with the correct next action. </p>

                    <div class="embed-responsive embed-responsive-16by9 w-50 mx-auto d-block">
                    <iframe src="https://www.youtube.com/embed/M_wdpGgWFk0" alt="An introduction video to our work in the Social Robotics Lab" align="center" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  </div>

                  <h3 class="mb-5 pt-lg-5"> Previous Projects </h3>


                </div>
            </section>
            <hr class="m-0" />
            <!-- Awards-->
            <section class="resume-section" id="contact">
                <div class="resume-section-content">
                    <h2 class="mb-5">Contact</h2>

                    <p> Sanne van Waveren <br>
                        PhD student Social Robotics <br>
                        KTH Royal Institute of Technology <br>
                        <i> Robotics, Perception and Learning (RPL) </i> <br>
                        Lindstedtsvägen 24, 4th floor <br>
                        SE-100 44 Stockholm, Sweden </p>

                        <p><a href="mailto:sannevw@kth.se"> sannevw@kth.se </a></p>
                        <p><a href="http://www.kth.se/profile/sannevw"> kth.se/profile/sanne </a></p>


                        <div class="social-icons">
                            <a class="social-icon" href="https://gist.github.com/Sannevw"><i class="fab fa-github"></i></a>
                            <a class="social-icon" href="https://twitter.com/sannevanwaveren?s=09"><i class="fab fa-twitter"></i></a>
                            <a class="social-icon" href="https://linkedin.com/in/svwaveren"><i class="fab fa-linkedin"></i></a>
                        </div>

                    <!-- <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Google Analytics Certified Developer
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Mobile Web Specialist - Google Certification
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            1
                            <sup>st</sup>
                            Place - University of Colorado Boulder - Emerging Tech Competition 2009
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            1
                            <sup>st</sup>
                            Place - University of Colorado Boulder - Adobe Creative Jam 2008 (UI Design Category)
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            2
                            <sup>nd</sup>
                            Place - University of Colorado Boulder - Emerging Tech Competition 2008
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            1
                            <sup>st</sup>
                            Place - James Buchanan High School - Hackathon 2006
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            3
                            <sup>rd</sup>
                            Place - James Buchanan High School - Hackathon 2005
                        </li>
                    </ul> -->
                </div>
            </section>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
